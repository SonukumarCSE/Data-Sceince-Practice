{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
        "# application."
      ],
      "metadata": {
        "id": "JBTDm2fp9EoF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Min-Max scaling is method to feature scaling through which we will able to put the data into the desired range.\n",
        "if we are working on any dataset and trying to build the model and value present in the dataset is large and if the model need to find the distance between the two point then it will be quite manageble for small data\n",
        "but if dataset size is large and the value is very big in that situation we need feature scaling method to put all the data into minimum range.\n",
        "in min-max scaling we put all the data between 1 the formula is :\n",
        "\n",
        "x(scaled) = (x(i)-x(min))/(x(max)-x(min))\n",
        "\n",
        "by using this formula we find the new value if we want use any library then we can go and use sklearn Minmaxscaler() function in that we can do all the fit tranfrom using their function.\n",
        "\n"
      ],
      "metadata": {
        "id": "48ENPWKhtj_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
        "# Provide an example to illustrate its application."
      ],
      "metadata": {
        "id": "2YGOwriRvLQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unit vector technique is one of the feture scaling method through which we will be able to do the feature scaling and bring the large amount and set of data into desirable range. this will be very managble and easy to predict and build the model.\n",
        "\n",
        "in the unit vector technique we basically concern about the direction of the vector, for this we divide the the magnitude of the axis point and make the entire magnitude of 1\n",
        "\n",
        "it is different from min max\n",
        "in min max the range is [0,1] but in this the magnitude is 1\n",
        "we use min max when we need the value in smaller range while unit vector technique is used for the direction concern model"
      ],
      "metadata": {
        "id": "yqJVF-CqvqnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
        "# example to illustrate its application."
      ],
      "metadata": {
        "id": "nqxLHYiAwfcz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA is technique through which we extract the most importance data from the data set and mainly this done because the dataset is very large it is hard to train on the large dataset that's why we try to select the most importance data from the dataset and train the model in this pca is one of the technique in doing this task.\n",
        "\n",
        "in PCA we mainly reduce the column size if the dataset is containing 2 column and if we plot the graph the it is coming (x,y) then in that case we select the one axis and go for the model building.\n",
        "\n",
        "this reduction of two axes in one this reduce the dimension and run time of the model\n"
      ],
      "metadata": {
        "id": "2jvtOttEwmoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
        "# Extraction? Provide an example to illustrate this concept."
      ],
      "metadata": {
        "id": "oKwloaWoyekF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature extraction is the process in which we try to bring the dfferent type of data into the most conponent of the data and we extract the most important part of the data and represent for the model building\n",
        "\n",
        "it reduces the dimension of the dataset"
      ],
      "metadata": {
        "id": "v4lm83f3yiWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
        "# contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
        "# preprocess the data."
      ],
      "metadata": {
        "id": "quw7Z6R61biN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for the recommeded system we will try hit the most relavent customer and suggest their required item for this we need to find the relation between the custome and food\n",
        "what type of food that customer eat\n",
        "what is the price range of the customer\n",
        "\n",
        "\n",
        "and we also check the best rated and good delivery time restaurant for this\n",
        "and we can also check type of food that customer liked\n",
        "\n",
        "for all this we need to find the similarity score between these parameter for this we will find the distnce means how similar and how close to that customer\n",
        "for this we will go for the calculation.\n",
        "if the dataset is very large and finding these score will tough for the large dataset and model building also be a tough task.\n",
        "\n",
        "for this we will do min max scaling in which we will bring all the dataset into the range [0,1] it will become easy for us to find the score.\n"
      ],
      "metadata": {
        "id": "6pXLQfVV1icv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
        "# features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
        "# dimensionality of the dataset."
      ],
      "metadata": {
        "id": "YMwwZnPY2nRu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pca is technique to reduce the dimension of the data and extract the most important data from the dataset it will reduce the overfitting case and model will train properly"
      ],
      "metadata": {
        "id": "_Gyt1Fo35gQN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xGpNrj464ZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
        "values to a range of -1 to 1."
      ],
      "metadata": {
        "id": "4mb_dYEy6627"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "scaler = MinMaxScaler()\n",
        "data = np.array([[1], [5], [10], [15], [20]])\n",
        "data = scaler.fit_transform(data)\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7lwE5i767bc",
        "outputId": "1645674d-c0f0-4adc-8ac0-88b8c39fcf48"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.        ]\n",
            " [0.21052632]\n",
            " [0.47368421]\n",
            " [0.73684211]\n",
            " [1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IKjCwk87VHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
        "Feature Extraction using PCA. How many principal components would you choose to retain, and why?"
      ],
      "metadata": {
        "id": "W3GEZ4BR73Et"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMpS_QYp73uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA is technique where we can reduce the most important feature and reduce it into two so we need two column and component analysis 1 and componenet analysis 2 where we can store the result."
      ],
      "metadata": {
        "id": "_Ivrg8si8jSi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJhFMrqP8yzP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}